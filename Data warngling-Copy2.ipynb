{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import requests\n",
    "import os\n",
    "import datetime\n",
    "import re\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import zipfile\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "import json\n",
    "from timeit import default_timer as timer\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv as a Pandas DataFrame\n",
    "twitter_enhanced = pd.read_csv('twitter-archive-enhanced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using requests library to download tsv file hosted on udacity server programmatically\n",
    "\n",
    "url=\"https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv\"\n",
    "file_name = 'image-predictions.tsv'\n",
    "response = requests.get(url)\n",
    "with open('image-predictions.tsv', 'wb') as file:\n",
    "    file.write(response.content)\n",
    "    \n",
    "image_predictions  = pd.read_csv('image-predictions.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n",
      "Error: tweet missing\n"
     ]
    }
   ],
   "source": [
    "# Query Twitter API for each tweet in the Twitter archive and save JSON in a text file\n",
    "# These are hidden to comply with Twitter's API terms and conditions\n",
    "consumer_key = 'wLIikXN2Mm6L4k9hUGpKw0DMa'\n",
    "consumer_secret = '32j7zmDP0Ni9FykX1X28tOHjz817coLgRr07wXt1g2aWMhaHTM'\n",
    "access_token = 'AAAAAAAAAAAAAAAAAAAAAJboLAEAAAAAoNfZWfIMk22d7mLAlC1%2BnQ3uA8s%3DiFllYaK5kctILsN6STQB81EtVcZora2U4fiUQPeL4RaO2dZnOt'\n",
    "access_secret = 'ljAwfo0WuuWOXrnZnPnQFHGXrzn7TI5aBVzS0cXN55d5F'\n",
    "\n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "tweet_ids = twitter_enhanced.tweet_id.values\n",
    "\n",
    "with open('tweet_json.txt', 'w') as output:\n",
    "    for tweet_id in tweet_ids:\n",
    "        try:\n",
    "            tweet = api.get_status(tweet_id, tweet_mode='extended')\n",
    "            json.dump(tweet._json, output)\n",
    "            output.write('\\n')\n",
    "        except tweepy.TweepError:\n",
    "            print('Error: tweet missing')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting relevant JSON data to dataframe\n",
    "\n",
    "tweets_list =[]\n",
    "\n",
    "with open('tweet_json.txt') as json_file:\n",
    "    for line in json_file:\n",
    "    \n",
    "        tweets_dict = {}\n",
    "        tweets_json = json.loads(line)\n",
    "        \n",
    "        try:\n",
    "            tweets_dict['tweet_id'] = tweets_json['extended_entities']['media'][0]['id']\n",
    "        except:\n",
    "            tweets_dict['tweet_id'] = 'na'\n",
    "\n",
    "        tweets_dict['retweet_count'] = tweets_json['retweet_count']\n",
    "        tweets_dict['favorite_count'] = tweets_json['favorite_count']\n",
    "        \n",
    "        tweets_list.append(tweets_dict)\n",
    "\n",
    "tweet_json2 = pd.DataFrame(tweets_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing Data: Quality and Tidiness Issues\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_enhanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_json2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# progrmmatic assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a basic summary of the DataFrame using .info\n",
    "twitter_enhanced.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_enhanced.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_enhanced.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_enhanced.name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether rating_numerator is always filled\n",
    "twitter_enhanced.rating_numerator.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_enhanced.rating_denominator.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_enhanced.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Checking for duplicated rows across all columns.\n",
    "sum(twitter_enhanced.duplicated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_enhanced.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quality:\n",
    "\n",
    "1.The timestamp column has dates in string form(object).\n",
    "\n",
    "2.the columns doggo, floofer, pupper and puppo could be collapsed into a  column\n",
    "\n",
    "3.archive: column \"expanded URLs\" has missing values, duplicates and unnecessary links\n",
    "\n",
    "4.not all dog names are filled\n",
    "\n",
    "5.Some of the rows from the tail() output above have invalid strings in the name column \"a\"\n",
    "\n",
    "6.Missing data in name and stages columns showing as 'None'\n",
    "\n",
    "tidiness:\n",
    "1.day,month,year are in one column\n",
    "\n",
    "\n",
    "2.there are unwanted columns (retweeted_status_timestamp, retweeted_status_user_id, retweeted_status_id ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_predictions.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_predictions.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_predictions.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_predictions.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_predictions.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quality:\n",
    "7.Nondescriptive column headers (\"p1\" and \"p1_conf\")\n",
    "\n",
    "tidiness:\n",
    "3.The column \"jpg_url\" will be removed since url data is already contained in the twitter enhanced data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_json2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_json2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_json2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_json2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_json2.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quality:\n",
    "\n",
    "8.non-numeric values for the \"tweet_id\" inputs which will need to be removed after merging data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy dataframes for cleaning purposes\n",
    "twitter_enhanced_clean = twitter_enhanced.copy()\n",
    "image_predictions_clean = image_predictions.copy()\n",
    "tweet_json2_clean = tweet_json2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#p1, p2, p3: dog breed names are not all in lowercase\n",
    "#Define\n",
    "\n",
    "#Turn them into lower case\n",
    "\n",
    "#Code\n",
    "\n",
    "\n",
    "twitter_enhanced_clean['p1'] = twitter_enhanced_clean['p1'].str.lower()\n",
    "twitter_enhanced_clean['p2'] = twitter_enhanced_clean['p2'].str.lower()\n",
    "twitter_enhanced_clean['p3'] = twitter_enhanced_clean['p3'].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "\n",
    "twitter_enhanced_clean.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define\n",
    "# The \"p1\" and \"p1_conf\" columns will be renamed with more explanatory titles.\n",
    "\n",
    "# Code\n",
    "new_col_names = {'p1':'dog_breed_prediction', 'p1_conf':'prediction_confidence'}\n",
    "\n",
    "image_predictions_clean.rename(columns= new_col_names, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "list(image_predictions_clean.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define\n",
    "# Finding non-numeric values for \"tweet_id\"\n",
    "\n",
    "# Code\n",
    "nn_index_list = []\n",
    "\n",
    "for i in range(0, len(tweet_json2_clean.tweet_id)):\n",
    "    if type(tweet_json2_clean.tweet_id[i]) != int:\n",
    "        nn_index_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in nn_index_list:\n",
    "    tweet_json2_clean.drop(tweet_json2_clean[tweet_json2_clean.index == i].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "tweet_json2_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index\n",
    "tweet_json2_clean = tweet_json2_clean.reset_index()\n",
    "del tweet_json2_clean['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE: Delete retweets by filtering the NaN of retweeted_status_user_id\n",
    "twitter_enhanced_clean = twitter_enhanced_clean[pd.isnull(twitter_enhanced_clean['retweeted_status_user_id'])]\n",
    "\n",
    "#TEST\n",
    "print(sum(twitter_enhanced_clean.retweeted_status_user_id.value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define tidiness\n",
    "#remove unwanted columns (retweeted_status_timestamp, retweeted_status_user_id, retweeted_status_id,... ) \n",
    "# Code\n",
    "drop_cols = ['in_reply_to_status_id','in_reply_to_user_id','retweeted_status_id',\\\n",
    "             'retweeted_status_user_id','retweeted_status_timestamp']\n",
    "\n",
    "\n",
    "twitter_enhanced_clean.drop(drop_cols, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST\n",
    "list(twitter_enhanced_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define\n",
    "#Remove those missing values in expanded_urls column by .dropna\n",
    "\n",
    "#Code\n",
    "twitter_enhanced_clean.dropna(subset=['expanded_urls'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "\n",
    "\n",
    "twitter_enhanced_clean.expanded_urls.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define:\n",
    "# Delete tweets with no pictures\n",
    "#Code\n",
    "image_predictions_clean = image_predictions_clean.drop_duplicates(['jpg_url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "len(image_predictions_clean[image_predictions_clean.jpg_url.duplicated()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define\n",
    "#merging the 3 dataframes into one. And then we will have only 1 dataframe to clean and process.\n",
    "\n",
    "#code\n",
    "\n",
    "twitter_enhanced_clean = pd.merge(left=twitter_enhanced_clean,\n",
    "                                  right=tweet_json2_clean, left_on='tweet_id', right_on='tweet_id', how='inner')\n",
    "twitter_enhanced_clean = twitter_enhanced_clean.merge(image_predictions_clean, on='tweet_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "twitter_enhanced_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Melt the doggo, floofer, pupper and puppo columns to dogs and dogs_stage column.\n",
    "\n",
    "#CODE:\n",
    "\n",
    "twitter_enhanced_clean = pd.melt(twitter_enhanced_clean, id_vars=['tweet_id',                                          \n",
    "                                                                'timestamp_y',\n",
    "                                                                  'timestamp_x',\n",
    "                                                                'text',\n",
    "                                                                'rating_numerator',\n",
    "                                                                'rating_denominator',\n",
    "                                                                'name'],\n",
    "                               var_name='dogs', value_name='dogs_stage')\n",
    "\n",
    "#CODE: drop dogs\n",
    "twitter_enhanced_clean = twitter_enhanced_clean.drop('dogs', 1)\n",
    "\n",
    "#CODE: Sort by dogs_stage then drop duplicated based on tweet_id except the last occurrence\n",
    "twitter_enhanced_clean = twitter_enhanced_clean.sort_values('dogs_stage').drop_duplicates(subset='tweet_id', \n",
    "                                                                                        keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melt_columns = ['doggo', 'floofer', 'pupper', 'puppo']\n",
    "stay_columns = [x for x in twitter_enhanced_clean.columns.tolist() if x not in melt_columns]\n",
    "\n",
    "# Melt the the columns into values\n",
    "twitter_enhanced_clean = pd.melt(twitter_enhanced_clean, id_vars = stay_columns, value_vars = melt_columns, \n",
    "                         var_name = 'stages', value_name = 'dogs_stage')\n",
    "\n",
    "# Delete column 'stages'\n",
    "twitter_enhanced_clean = twitter_enhanced_clean.drop('stages', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "twitter_enhanced_clean.info()\n",
    "twitter_enhanced_clean.dogs_stage.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define\n",
    "#correct all datatypes by changing the datatypes of the columns.\n",
    "\n",
    "#Code\n",
    "\n",
    "twitter_enhanced_clean['tweet_id'] = twitter_enhanced_clean['tweet_id'].astype(str)\n",
    "twitter_enhanced_clean['timestamp_y'] = pd.to_datetime(twitter_enhanced_clean.timestamp_y)\n",
    "twitter_enhanced_clean['timestamp_x'] = pd.to_datetime(twitter_enhanced_clean.timestamp_x)\n",
    "twitter_enhanced_clean['dogs_stage'] = twitter_enhanced_clean['dogs_stage'].astype('category')\n",
    "twitter_enhanced_clean['rating_numerator'] = twitter_enhanced_clean['rating_numerator'].astype(float)\n",
    "twitter_enhanced_clean['rating_denominator'] = twitter_enhanced_clean['rating_denominator'].astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "\n",
    "#check the data types of each column\n",
    "twitter_enhanced_clean.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Define:\n",
    "#Check for incorrect dog names, and make it as Nan then put it as \"None\" rows.\n",
    "\n",
    "#Code:\n",
    "\n",
    "twitter_enhanced_clean.name.sort_values()\n",
    "\n",
    "#check for unclear dog names\n",
    "twitter_enhanced_clean['name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define:\n",
    "#replace incorrect name with NaN\n",
    "twitter_enhanced_clean.name.replace(['such', 'an', 'the', 'just', 'by', 'a', 'mad', 'old', 'space', \n",
    "             'quite', 'actually', 'infuriating', 'all', 'officially', 'my', 'unacceptable', 'incredibly',\n",
    "              'not', '0', 'life', 'one', 'his', 'very'],np.NaN, inplace =True)\n",
    "\n",
    "#put all NaN values in \"None\"\n",
    "twitter_enhanced_clean['name'].fillna(value=\"None\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "twitter_enhanced_clean.name.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define\n",
    "# Clean data by dropping duplicates row and not meaningful columns.\n",
    "\n",
    "#Code\n",
    "# Delete duplicated tweet_id\n",
    "twitter_enhanced_clean = twitter_enhanced_clean.drop_duplicates()\n",
    "\n",
    "\n",
    "#Delete dog_stage duplicates\n",
    "twitter_enhanced_clean = twitter_enhanced_clean.sort_values('dogs_stage').drop_duplicates('tweet_id', keep = 'last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "\n",
    "twitter_enhanced_clean.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate timestamp into day - month - year (3 columns)\n",
    "\n",
    "#code\n",
    "\n",
    "#extract year, month and day to new columns\n",
    "twitter_enhanced_clean['year'] = twitter_enhanced_clean['timestamp_y'].dt.year\n",
    "twitter_enhanced_clean['month'] = twitter_enhanced_clean['timestamp_y'].dt.month\n",
    "twitter_enhanced_clean['day'] = twitter_enhanced_clean['timestamp_y'].dt.day\n",
    "twitter_enhanced_clean['year'] = twitter_enhanced_clean['timestamp_x'].dt.year\n",
    "twitter_enhanced_clean['month'] = twitter_enhanced_clean['timestamp_x'].dt.month\n",
    "twitter_enhanced_clean['day'] = twitter_enhanced_clean['timestamp_x'].dt.day\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST\n",
    "list(twitter_enhanced_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define\n",
    "# drop timestamp column\n",
    "\n",
    "#code\n",
    "twitter_enhanced_clean = twitter_enhanced_clean.drop('timestamp_x', 1)\n",
    "twitter_enhanced_clean = twitter_enhanced_clean.drop('timestamp_y', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST\n",
    "list(twitter_enhanced_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#name: this column has some missing values and some of the names are not real dog names but articles or adjectives.\n",
    "#Define\n",
    "\n",
    "#Replace those not-real-dog-names with None\n",
    "\n",
    "#Code\n",
    "\n",
    "\n",
    "not_dog_names = twitter_enhanced_clean.loc[(twitter_enhanced_clean.name.str.islower())].name.value_counts().index.tolist()\n",
    "not_dog_names.append('None')\n",
    "not_dog_names\n",
    "\n",
    "for name in not_dog_names:\n",
    "    twitter_enhanced_clean.loc[twitter_enhanced_clean.name == name, 'name'] = None\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "\n",
    "twitter_enhanced_clean.name.value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# save master data frame\n",
    "twitter_enhanced_clean.to_csv('twitter_archive_analyze.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze&Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('twitter_archive_analyze.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#which kind of source are people using the most?\n",
    "\n",
    "df.source.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " most people using Twitter for iPhone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Most popular names\n",
    "\n",
    "df.name.value_counts().head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the total occurrences of each dog name \n",
    "twitter_enhanced_clean.name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dog_type = ['pupper', 'doggo', 'puppo', 'floofer', 'multiple']\n",
    "dog_counts = [184, 72, 23, 9, 5]\n",
    "\n",
    "fig,ax = plt.subplots(figsize = (12,6))\n",
    "ax.bar(dog_type, dog_counts, width = 0.8)\n",
    "ax.set_ylabel('Dog Count')\n",
    "ax.set_xlabel('Category')\n",
    "plt.title(\"Most Common Dog Category\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['name'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_enhanced_clean.drop(twitter_enhanced_clean.query('(dog_types == \"None\")').index ,inplace=True)\n",
    "sns.boxplot(x=\"dog_types\", y=\"favorites\", data=twitter_enhanced_clean).set_title('Dog categories with total of favorites');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dog_type = df.groupby('dog_type').filter(lambda x: len(x) >= 25)\n",
    "\n",
    "df_name['dog_type'].value_counts().plot(kind = 'barh')\n",
    "plt.title('Histogram of the Most Rated Dog Type')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Type of dog')\n",
    "\n",
    "fig = plt.gcf() \n",
    "fig.savefig('output.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate rating ratio\n",
    "df['rating_ratio'] = df['rating_numerator']/df['rating_denominator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#discover the ratio of dog rating distribution\n",
    "\n",
    "\n",
    "#Here after we calculated the ratio of dog rating from(rating numerator /rating denominator)rate, we can see that the chart takes normally distribution of dogs rating.\n",
    "\n",
    "sns.distplot(df.rating_ratio).set_title('Ratio of dog rating distribution');\n",
    "plt.xlabel('count of ratio of dog rating')\n",
    "plt.ylabel('count of ratio rating')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data partition on basis of Life stage of dogs\n",
    "\n",
    "dogs_stage_count = list(twitter_enhanced_clean[df['dogs_stage'] != 'None']['dogs_stage'].value_counts())[0:4]\n",
    "dogs_stages = df[df['dogs_stage'] != 'None']['dogs_stage'].value_counts().index.tolist()[0:4]\n",
    "explode = (0.2, 0.1, 0.1, 0.1) \n",
    "\n",
    "figure1, axis1 = plt.subplots()\n",
    "axis1.pie(dogs_stage_count, explode = explode, labels = dogs_stages, shadow = True, startangle = 90)\n",
    "axis1.axis('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyses\n",
    "Dogs in Pupper stage of dog life cycle get most tweets, which is expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(15, 10))\n",
    "\n",
    "plt.bar([1, 2, 3, 4, 5, 6, 7], tick_label=['doggo', 'doggo, floofer', 'doggo, pupper', 'doggo, puppo', \n",
    "                                                       'floofer','pupper', 'puppo'])\n",
    "plt.title('Most popular dog types')\n",
    "plt.xlabel('Dog type', weight='bold')\n",
    "plt.ylabel('Count', weight='bold')\n",
    "plt.savefig('most_pop_types.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "breeds = ['golden_retriever', 'labrador_retriever', 'pembroke', 'chihuahua', 'samoyed', 'french_bulldog']\n",
    "y_position = np.arange(len(breeds))\n",
    "\n",
    "plt.bar(y_position, align='center', alpha=0.5, lambda t: t[0]*t[1])\n",
    ")\n",
    "\n",
    "\n",
    "plt.xticks(y_position, breeds)\n",
    "plt.xticks(rotation=30)\n",
    "plt.ylabel(\"Average rating\")\n",
    "plt.title(\"Average rating of popular dogs\")\n",
    "\n",
    "plt.savefig('dog_ratings.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the top 10 Dog names by frequency\n",
    "plt.figure(figsize=(12, 8))\n",
    "dog_names = twitter_enhanced_clean.name.value_counts().nlargest(10).plot(kind = 'barh');\n",
    "dog_names.set_title('Dog Name Frequency');\n",
    "dog_names.set_xlabel('Frequency');\n",
    "dog_names.set_ylabel('Dog Name');\n",
    "dog_names.set_xlim(1, 10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common dog name is Cooper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting rows where the breed is identified\n",
    "df = df[pd.notnull(df.dog_breed_prediction)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Piechart\n",
    "plt.rcParams['figure.figsize']=(15,15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Piechart\n",
    "plt.rcParams['figure.figsize']=(15,15)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "df.dog_breed_prediction.value_counts(sort=True).plot.pie(startangle=270, pctdistance=0.8, radius = 0.9)\n",
    "plt.title('Distributions of breeds in the Data as identified using a picture recognition software')\n",
    "plt.ylabel('')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
